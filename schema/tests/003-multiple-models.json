{
    "modelServer": {
      "name": "developer-model-service",
      "url": "https://example.com",
      "owner": "example-user",
      "description": "Developer model service running on vLLM",
      "usage": "Model server usage description",
      "tags": ["vLLM", "granite", "ibm"],
      "API": {
        "url": "https://api.example.com",
        "type": "openapi",
        "spec": "https://raw.githubusercontent.com/redhat-ai-dev/model-catalog-example/refs/heads/main/developer-model-service/openapi.json",
        "tags": ["openapi", "openai", "3scale"]
      },
      "lifecycle": "production",
      "authentication": true
    },
    "models": [
      {
        "name": "ibm-granite-20b",
        "description": "IBM Granite 20b model running on vLLM",
        "artifactLocationURL": "https://huggingface.co/ibm-granite/granite-20b-code-instruct",
        "tags": ["IBM", "granite", "vllm", "20b"],
        "owner": "example-user",
        "lifecycle": "production"
      },
      {
        "name": "mistral-7b",
        "description": "Mistral 7b model running on vLLM",
        "artifactLocationURL": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2",
        "tags": ["mistralai", "mistral", "vllm", "7b"],
        "owner": "example-user",
        "lifecycle": "production"
      },
      {
        "name": "gemma-2-2b",
        "description": "Google Gemma 2 2b model running on vLLM",
        "artifactLocationURL": "https://huggingface.co/google/gemma-2-2b",
        "tags": ["google", "gemma"],
        "owner": "example-user",
        "lifecycle": "production"
      }
    ]
  }